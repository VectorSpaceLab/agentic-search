<div align="center">
<h1> ReasonEmbed: Enhanced Text Embeddings for Reasoning-Intensive Document Retrieval </h1>
</div>


## Introduction

We propose **ReasonEmbed**, a new text embedding model for reasoning-intensive document retrieval based on innovations of how synthetic data is generated and used. Our work includes the following technical contributions.
1. We design a novel data synthesis method, called **ReMixer**.
2. We introduce a self-adaptive training method tailored for our synthetic data, termed **Redapter**.
3. We implement ReasonEmbed based on multiple LLM backbones of varying model sizes, which achieve **state-of-the-art (SOTA) performance** on reasoning-intensive document retrieval tasks. Notably, our model built on Qwen3-4B reaches an nDCG@10 score of 37.1 on the [BRIGHT](https://brightbenchmark.github.io/) benchmark, which already surpasses all existing text embedding models. While the Qwen3-8B based varient improves the performance to 38.1. Moreover, on the [R2MED](https://r2med.github.io/) benchmark, ReasonEmbed-Qwen3-8B attains an nDCG@10 score of 43.18, surpassing all of the existing models by a large margin and leading to new SOTA performance.

For more details, please refer to our [paper (TBA)]().

## Open-Source Resources

### Model Checkpoints

TBA

### Evaluation Code and Scripts

TBA

### Data and Synthesis Code

TBA

### Training Code and Scripts

TBA


## Citation

If you find this repository useful, please consider giving a star ‚≠ê and citation:
```
TBA
```
